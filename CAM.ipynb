{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "front-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KYH\\.conda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pathlib\n",
    "import scipy as sp\n",
    "\n",
    "from scipy.ndimage import label\n",
    "from skimage.measure import regionprops\n",
    "from matplotlib import patches\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "import time\n",
    "\n",
    "config =  ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bb85598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cam(img_path, class_idx, cam_model):\n",
    "    img = Image.open(img_path).resize((224, 224))\n",
    "    img_arr = np.asarray(img)[:, :, :3] / 255.\n",
    "    img_array = np.expand_dims(img_arr, 0)\n",
    "    \n",
    "    conv_outputs, prediction = cam_model.predict(img_array) # CAM 생성에 필요한 값들\n",
    "    class_weights = cam_model.layers[-1].get_weights()[0]\n",
    "\n",
    "    cam = np.dot(conv_outputs, class_weights[:,class_idx])\n",
    "    \n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    cam_img = cv2.resize(cam_img, (224, 224))\n",
    "    cam_img = np.uint8(255 * cam_img)\n",
    "    \n",
    "    return img_arr, cam_img, results\n",
    "\n",
    "def avg_cam(img_path, cam_model):\n",
    "    img = Image.open(img_path).resize((224, 224))\n",
    "    img_arr = np.asarray(img)[:, :, :3] / 255.\n",
    "    img_array = np.expand_dims(img_arr, 0)\n",
    "    \n",
    "    conv_outputs, prediction = cam_model.predict(img_array) # CAM 생성에 필요한 값들\n",
    "    class_weights = cam_model.layers[-1].get_weights()[0]\n",
    "    \n",
    "    ## calculate cam\n",
    "    cam = np.zeros((224,224), dtype=float)\n",
    "    for class_idx in range(7):\n",
    "        cam += np.dot(conv_outputs, class_weights[:,class_idx])\n",
    "    \n",
    "    cam /= 7\n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    cam_img = cv2.resize(cam_img, (224, 224))\n",
    "    cam_img = np.uint8(255*cam_img)\n",
    "    \n",
    "    return img_arr, cam_img, results\n",
    "\n",
    "def back_remove_avg_cam(img_path, class_idx, cam_model):  \n",
    "    # Input image resize\n",
    "    img = Image.open(img_path).resize((224, 224))\n",
    "    img_arr = np.asarray(img)[:, :, :3] / 255.\n",
    "    img_array = np.expand_dims(img_arr, 0)\n",
    "\n",
    "    conv_outputs, prediction = cam_model.predict(img_array) # CAM 생성에 필요한 값들\n",
    "    class_weights = cam_model.layers[-1].get_weights()[0]\n",
    "    \n",
    "    ## calculate cam\n",
    "    cam = np.zeros((14,14), dtype=float)\n",
    "    for class_idx in range(1,8):\n",
    "        cam += np.dot(conv_outputs[0, :, :, :], class_weights[:,class_idx])\n",
    "\n",
    "    # AvgCAM\n",
    "    cam /= 7\n",
    "\n",
    "    # BR-AvgCAM\n",
    "    back_cam = np.dot(conv_outputs[0, :, :, :], class_weights[:,0])\n",
    "    cam = cam - back_cam # Back CAM remove\n",
    "   \n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    cam_img = cv2.resize(cam_img, (224, 224))\n",
    "    cam_img = np.uint8(255*cam_img)\n",
    "\n",
    "    return img_arr, cam_img, results\n",
    "\n",
    "def back_remove_cam(img_path, class_idx, cam_model):  \n",
    "    img = Image.open(img_path).resize((224, 224))\n",
    "    img_arr = np.asarray(img)[:, :, :3] / 255.\n",
    "    img_array = np.expand_dims(img_arr, 0)\n",
    "    \n",
    "    conv_outputs, prediction = cam_model.predict(img_array) # CAM 생성에 필요한 값들\n",
    "    class_weights = cam_model.layers[-1].get_weights()[0]\n",
    "    \n",
    "    ## calculate cam\n",
    "    cam = np.dot(conv_outputs, class_weights[:,class_idx])\n",
    "    \n",
    "    back_cam = np.dot(conv_outputs, class_weights[:,0])\n",
    "    cam = cam - back_cam\n",
    "        \n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    cam_img = cv2.resize(cam_img, (224, 224))\n",
    "    cam_img = np.uint8(255*cam_img)\n",
    "    \n",
    "    return img_arr, cam_img, results\n",
    "\n",
    "def get_label(xml):\n",
    "    p_size = xml.find('size')\n",
    "    p_box = xml.find('object').find('bndbox')\n",
    "    size = {'width':int(p_size.find('width').text),'height': int(p_size.find('height').text)}\n",
    "    box = {'xmin':int(p_box.find('xmin').text), 'ymin' : int(p_box.find('ymin').text),'xmax': int(p_box.find('xmax').text),'ymax': int(p_box.find('ymax').text)}\n",
    "    xmin, ymin, xmax, ymax = box['xmin'] / size['width'] * 224, box['ymin'] / size['height'] * 224, box['xmax'] / size['width'] * 224,box['ymax'] / size['height'] * 224\n",
    "    w, h = xmax - xmin, ymax - ymin\n",
    "    return {'xmin':xmin, 'ymin':ymin, 'xmax':xmax,'ymax':ymax,'w':w, 'h':h}\n",
    "\n",
    "def generate_bbox(img, cam, threshold):\n",
    "    labeled, nr_objects = label(cam > threshold)\n",
    "    props = regionprops(labeled)\n",
    "    \n",
    "    init = props[0].bbox_area\n",
    "    bbox = list(props[0].bbox)\n",
    "    for b in props:\n",
    "        if init < b.bbox_area:\n",
    "            bbox = list(b.bbox)\n",
    "    return bbox\n",
    "\n",
    "#boxA[0] : min x, boxA[1] : min y, boxA[2] : max x, boxA[3] : max y\n",
    "def IoU(boxA, boxB):\n",
    "    xA = max(boxA[1], boxB['xmin'])\n",
    "    yA = max(boxA[0], boxB['ymin'])\n",
    "    xB = min(boxA[3], boxB['xmax'])\n",
    "    yB = min(boxA[2], boxB['ymax'])\n",
    "\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB['xmax'] - boxB['xmin'] + 1) * (boxB['ymax'] - boxB['ymin'] + 1)\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def avg_blur(bbox, img):\n",
    "    x = bbox[1]\n",
    "    y = bbox[0]\n",
    "    w = bbox[3] - bbox[1]\n",
    "    h = bbox[2] - bbox[0]\n",
    "    \n",
    "    roi = img[y:y+h, x:x+w]\n",
    "    roi = cv2.blur(roi, (9,9))\n",
    "    img[y:y+h, x:x+w] = roi\n",
    "    \n",
    "    return img\n",
    "\n",
    "def gaussian_blur(bbox, img):\n",
    "    x = bbox[1]\n",
    "    y = bbox[0]\n",
    "    w = bbox[3] - bbox[1]\n",
    "    h = bbox[2] - bbox[0]\n",
    "    \n",
    "    roi = img[y:y+h, x:x+w]\n",
    "    roi = cv2.GaussianBlur(roi, (9,9), 0)\n",
    "    img[y:y+h, x:x+w] = roi\n",
    "    \n",
    "    return img\n",
    "\n",
    "def median_blur(bbox, img):\n",
    "    x = bbox[1]\n",
    "    y = bbox[0]\n",
    "    w = bbox[3] - bbox[1]\n",
    "    h = bbox[2] - bbox[0]\n",
    "    \n",
    "    roi = img[y:y+h, x:x+w]\n",
    "    roi = cv2.medianBlur(roi.astype(np.uint8), 9)\n",
    "    img[y:y+h, x:x+w] = roi\n",
    "    \n",
    "    return img\n",
    "\n",
    "def bilateral_filter(bbox, img):\n",
    "    x = bbox[1]\n",
    "    y = bbox[0]\n",
    "    w = bbox[3] - bbox[1]\n",
    "    h = bbox[2] - bbox[0]\n",
    "    \n",
    "    roi = img[y:y+h, x:x+w]\n",
    "    roi = cv2.bilateralFilter(roi.astype(np.float32), 9, 75, 75)\n",
    "    img[y:y+h, x:x+w] = roi\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rubber-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f'./VGG16_VOC2012_7_back_1230')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "preceding-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_model = tf.keras.Model(model.input, outputs=(model.layers[-3].output, model.layers[-1].output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f203b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6212bd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 472 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = f'VOC2012_7_back_dataset/test'\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_ds = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0221d014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0background 0\n",
      "aeroplane 1\n",
      "bird 2\n",
      "car 3\n",
      "cat 4\n",
      "dog 5\n",
      "person 6\n",
      "train 7\n"
     ]
    }
   ],
   "source": [
    "for class_name, class_idx in test_ds.class_indices.items():\n",
    "    print(class_name, class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a879434",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2160/3938461823.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{test_dir}/train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimg_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mback_remove_avg_cam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{test_dir}/train/{sample[index]}'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcam_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'VOC2012/Annotations/{sample[index].replace(\"jpg\",\"xml\")}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2160/2834125819.py\u001b[0m in \u001b[0;36mback_remove_avg_cam\u001b[1;34m(img_path, class_idx, cam_model)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mcam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mcam\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# AvgCAM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "sample = os.listdir(f'{test_dir}/train')\n",
    "img_arr, cam, results = back_remove_avg_cam(f'{test_dir}/train/{sample[index]}', 7, cam_model)\n",
    "\n",
    "tree = parse(f'VOC2012/Annotations/{sample[index].replace(\"jpg\",\"xml\")}')\n",
    "box = get_label(tree)\n",
    "bbox = generate_bbox(img_arr, cam, 255*0.8)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(cam, cmap='jet', alpha=0.9)\n",
    "plt.imshow(img_arr, alpha=0.5)\n",
    "ax = plt.gca()\n",
    "\n",
    "xs = bbox[1]\n",
    "ys = bbox[0]\n",
    "w = bbox[3] - bbox[1]\n",
    "h = bbox[2] - bbox[0]\n",
    "\n",
    "rect = patches.Rectangle((xs, ys), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "rect = patches.Rectangle((box['xmin'], box['ymin']), box['w'], box['h'], linewidth=2, edgecolor='b', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(IoU(bbox, box))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7735c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
